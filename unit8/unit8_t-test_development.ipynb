{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the null hypothesis H0: There is no difference between temperature climatologies from 1951-1980 and 1991-2020!\n",
    "\n",
    "We use monthly mean data from station observations that are part of the GHCN data base. \n",
    "The code an extension of the code developed for the confidence interval calculations (see unit 7). The main purpose of this coding activity: Conduct a formal t-test and find stations and months for which we can reject the null hypothesis. In other words we want to explore where in NY and during which season we have the strongest data support for a significant warming.\n",
    "\n",
    "Note: In this notebook we read a list of station id numbers (and additional 'metadata' information) from a text file that has all of the NY stations listed. Many stations do not have complete time series over the whole time period 1951-2018, so those are discarded. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Code development\n",
    "\n",
    "### 1.1 Importing our own set of support functions\n",
    "\n",
    "In this script you notice we do not define the function for downloading the data from the ACIS server. \n",
    "\n",
    "Instead, we can separate the function definitions from our Notebook and import the functions with the same syntax that we use to import packages like _numpy_ or _scipy.stats_. This importing of Python code from separate files is known as import of _modules_. (The file is pure Python code and must have the extension *.py*.) \n",
    "\n",
    "Our Python script is called support.py (see GitHub repository unit8, download the script file, and upload it here into directory *unit8*). Note the ending must be .py for this Python code text file. This is referred to as 'import of modules'.\n",
    "\n",
    "**Download the file support.py from GitHub (see folder unit8) and upload it into the same folder where you have this notebook file. The file must be named _support.py_ !**\n",
    "\n",
    "\n",
    "Note: Packages are more complex, consisting of entire folders and subfolders with Python code. So modules are much simpler to maintain and a good first start to get your useful functions organized.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Importing all packages and our own module as spt\n",
    "\n",
    "And check what we imported and how the functions work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "import support as spt\n",
    "# new: use function help() to see the content of the imported module and the doc-string information\n",
    "help(spt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the file with the NY station data information (metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get station list from local file\n",
    "sidlist,latlist,lonlist,elevlist,namelist=spt.get_station_list(sid_code=\"USW\")\n",
    "print (\"number of stations starting with 'USW' (Airport stations)\",len(sidlist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Preparing the data for statistical calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P style=\"background-color:lightgreen;color:black;font-size:130%\">\n",
    "<BR>\n",
    "Check which stations have complete data, and  form a final list of stations to use.\n",
    "<BR>\n",
    "<BR>\n",
    "</P>\n",
    "\n",
    "\n",
    "**The code below is one 'basic' level approach to deal with storing all station data\n",
    "that have complete time series without any missing values.**\n",
    "\n",
    "Here we use a simple approach: \n",
    "- Access all the station data from the ACIS server. \n",
    "- For each station, the downloaded data is checked for missing values.\n",
    "- If data are complete for the whole period (1951 to 2018, see variable year1, year2 above), then the station metdata information (station id, latitude, longitude, elevation, and full station name) is appended to new lists.\n",
    "\n",
    "Once we have screened our station data we can do our calculation and plotting for any of those stations by selecting one of the station id names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varname=\"avgt\"\n",
    "year1,year2= 1951,2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"data complete between %4d and %4d?\" %(year1,year2))\n",
    "complete_sid=[]\n",
    "complete_lat=[]\n",
    "complete_lon=[]\n",
    "complete_elev=[]\n",
    "complete_name=[]\n",
    "i=0\n",
    "for station_id in sidlist:\n",
    "    x,y=spt.get_stationdata_monthly(station_id,varname,startyear=year1,endyear=year2)\n",
    "    if len(x)==0:\n",
    "        pass\n",
    "    else:\n",
    "        x=np.array(x)\n",
    "        y=np.array(y)\n",
    "        # check for completeness in data (no NAN allowed)\n",
    "        iuse=np.logical_and(x>dt.datetime(1950,12,31),x<dt.datetime(2021,1,1))\n",
    "        imiss=np.isnan(y[iuse])\n",
    "        if any(imiss): # NAN values detected in time series\n",
    "            pass\n",
    "            #print (3*\"-\"+\"station: \"+station_id+\" variable \"+varname+\" has NAN values.\")\n",
    "        else: # no NAN detected\n",
    "            print (3*\"+\"+\"station: \"+station_id+\" variable \"+varname+\" is complete.\")\n",
    "            complete_sid.append(station_id)\n",
    "            complete_lat.append(latlist[i])\n",
    "            complete_lon.append(lonlist[i])\n",
    "            complete_elev.append(elevlist[i])\n",
    "            complete_name.append(namelist[i])\n",
    "    i=i+1\n",
    "nstation=len(complete_sid)\n",
    "print (\"number of stations, number of stations with complete data\", i,nstation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"stations that are available\")\n",
    "for i,sid in enumerate(complete_sid): # new syntax\n",
    "    print (i,sid,complete_name[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P style=\"background-color:lightgreen;color:black;font-size:130%\">\n",
    "<BR>\n",
    "Read data for one of the stations stored in the list of complete stations.\n",
    "<BR>\n",
    "<BR>\n",
    "</P>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_index=0 #\n",
    "print (complete_sid[station_index])\n",
    "print (complete_name[station_index])\n",
    "x,y=spt.get_stationdata_monthly(complete_sid[station_index],\\\n",
    "                            varname,startyear=year1,endyear=year2)\n",
    "x=np.array(x)\n",
    "y=np.array(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P style=\"background-color:lightgreen;color:black;font-size:130%\">\n",
    "<BR>\n",
    "Select the data from x and y for the two 30 climate period: 1951-1980 and 1991-2020\n",
    "<BR>\n",
    "<BR>\n",
    "</P>\n",
    "    \n",
    "Assign the results to new variables and check with np.shape the dimensions and size of the data array. You should have 360 data left in the arrays. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create first subsample\n",
    "iclim1=np.logical_and(x>dt.datetime(1950,12,31),x<dt.datetime(1981,1,1))\n",
    "xclim1=x[iclim1]\n",
    "yclim1=y[iclim1]\n",
    "print(\"check climatology data sample 1:\")\n",
    "print(xclim1[0],\" - \",xclim1[-1])\n",
    "print(np.shape(yclim1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create second subsample\n",
    "iclim2=np.logical_and(x>dt.datetime(1990,12,31),x<dt.datetime(2021,1,1))\n",
    "xclim2=x[iclim2]\n",
    "yclim2=y[iclim2]\n",
    "print(\"check climatology data sample 2:\")\n",
    "print(xclim2[0],\" - \",xclim2[-1])\n",
    "print(np.shape(yclim2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P style=\"background-color:lightgreen;color:black;font-size:130%\">\n",
    "<BR>\n",
    "Calculate the mean and standard deviation for each month (using np.reshape)\n",
    "<BR>\n",
    "<BR>\n",
    "</P>\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhelp1=np.reshape(yclim1,newshape=(30,12))\n",
    "yhelp2=np.reshape(yclim2,newshape=(30,12))\n",
    "\n",
    "ymean1=np.mean(yhelp1,axis=0)\n",
    "ymean2=np.mean(yhelp2,axis=0)\n",
    "ystd1=np.std(yhelp1,axis=0)\n",
    "ystd2=np.std(yhelp2,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P style=\"background-color:lightgreen;color:black;font-size:130%\">\n",
    "<BR>\n",
    "Confidence intervals\n",
    "<BR>\n",
    "<BR>\n",
    "</P>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample size here is 30 years, but we should make it a data-dependent value.\n",
    "#n1, n2 = 30, 30\n",
    "n1= np.shape(yhelp1)[0] # rows are the years\n",
    "n2= np.shape(yhelp2)[0] # rows are the years (could be different from sample 1) \n",
    "df1=n1-1\n",
    "df2=n2-1\n",
    "alpha=0.95 # for both samples\n",
    "tint1=stats.t.interval(alpha,df1) # returns lists\n",
    "tint2=stats.t.interval(alpha,df2) # returns lists\n",
    "# arrays for the upper and lower confidence intervals\n",
    "cf1=np.zeros(shape=[2,12])\n",
    "cf2=np.zeros(shape=[2,12]) # a true independent copy \n",
    "for i in range(12):\n",
    "    cf1[:,i]=np.array(tint1)*ystd1[i]/np.sqrt(n1)\n",
    "    cf2[:,i]=np.array(tint2)*ystd2[i]/np.sqrt(n2)\n",
    "    i+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P style=\"background-color:purple;color:gold;font-size:130%\">\n",
    "<BR>\n",
    "Task 1: Present the climatologies in a graph or two that make it easy to see the differences between the two periods, and how much the confidence intervals overlap.\n",
    "<BR>\n",
    "<BR>\n",
    "</P>\n",
    "    \n",
    "- Tip: Check the function plt.errorbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(plt.errorbar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P style=\"background-color:purple;color:gold;font-size:130%\">\n",
    "<BR>\n",
    "Task 2: Calculate the t-test with the help of the function stats.ttest_ind. Choose a winter month and a summer month (or can you figure out how to apply the t-test to all months?). Where you expect to reject the null hypothesis and obtain the smallest p-value?\n",
    "\n",
    "<BR>\n",
    "<BR>\n",
    "</P>\n",
    "    \n",
    "Tip: Check out the help or google examples for the application of the function Scipy *stats.ttest_ind*.\n",
    "(see link below)\n",
    "\n",
    "Print out the essential information: \n",
    "- the difference in the mean, \n",
    "- the t-statistic, the p-value, \n",
    "- the test decision, \n",
    "- and interpretation of the sign if the difference (sign of the t-statistic).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(stats.ttest_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code for t-test calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code for plotting / printing the p-values\n",
    "# and decide if statistically significant at 5% significance level \n",
    "# (p<0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Summary and conclusion\n",
    "\n",
    "Some comments/remarks here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### References\n",
    "\n",
    "- [Introduction to import of modules](https://www.programiz.com/python-programming/modules)\n",
    "- [Function ttest_ind from scipy.stats](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html)\n",
    "- [Welch's form of the t-test](https://en.wikipedia.org/wiki/Welch%27s_t-test) (ttest_ind supports calculating this test statistic when we set the keyword parameter _equal_var=False_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P style=\"background-color:lightgreen;color:black;font-size:130%\">\n",
    "<BR>\n",
    "Optional Practice: Create a Pandas DataFrame and export to CSV file\n",
    "<BR>\n",
    "<BR>\n",
    "</P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take all lists objects with station metadata information and create a \n",
    "new DataFrame object. (see variables _sidlist_, _latlist_, _lonlist_, _elevlist_)\n",
    "    \n",
    "Show the first top rows of the DataFrame as a table.\n",
    "\n",
    "Then call the function that exports the DataFrame to a CSV file.\n",
    "\n",
    "\n",
    "The functions ('methods') to be used are: _df.head()_ and _df.to_csv('test.csv'_)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional practice:\n",
    "# Put the lists into a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
