{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ranking-sauce",
   "metadata": {},
   "source": [
    "# Example Script: Working with NYS Mesonet data \n",
    "\n",
    "### Available time range: 01/01/2017-12/31/2020\n",
    "\n",
    "### NOTE: 2017 is not complete (field stations were still installed in that year)\n",
    "### work with years 2018, 2019, 2020\n",
    "### Temporal resolution: hourly averages\n",
    "\n",
    "The time format over is good to work with, except for the change between \n",
    "Eastern Standard Time (EST) to Eastern Daylight Time (EDT).\n",
    "This is more than annoying for data analysis \n",
    "[(see here for ways how to deal with it in Python)](https://towardsdev.com/giant-mess-dealing-with-timezones-and-daylight-saving-time-in-python-7222d37658cf)\n",
    "\n",
    "### Locations: 126 stations\n",
    "\n",
    "\n",
    "### Meteorological observed variables include:\n",
    " - temperature\n",
    " - relative humidity\n",
    " - precipitation\n",
    " - wind \n",
    " - solar insolation\n",
    " \n",
    "### Data format: \n",
    "Data are arranged in form of a spreadsheet table.\n",
    "Rows are used to store the temporal data samples, colulmns are used to\n",
    "orangize the observations into meteorological variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-cheat",
   "metadata": {},
   "source": [
    "# Example: Tropical nights (tmin > 20.0 deg C)\n",
    "\n",
    "\n",
    "- Process all stations and create daily tmax time series for summer months June-July-August 2018.\n",
    "- create a new DataFrame with daily tmax in rows, stations organized in columns.\n",
    "- summary statistics: exceedance rates tmin >20.0 deg C\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twenty-cylinder",
   "metadata": {},
   "source": [
    "### We import a support package called pandas. \n",
    "More a about package import comes later.\n",
    "Here we just use it to give us access to Mesonet data in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quarterly-maker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code cell with import statements\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# for the reading and handling of the Mesonet data\n",
    "import pandas as pd\n",
    "# for supporting date and time \n",
    "import datetime as dt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "planned-nightlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_support(timestring,daily=False):\n",
    "    \"\"\"helper function to deal with the EST and EDT time zone problem\n",
    "    \n",
    "    Input parameter:\n",
    "        a string with date string (obtained from csv files)\n",
    "        daily (Boolean): keyword parameter toggles between daily and hourly \n",
    "                         datetime string support. Default is hourly.\n",
    "                         If True, daily is used, it does not read the hour/min information\n",
    "    Return value:\n",
    "        datetime object that include a time zone information\"\"\"\n",
    "    if timestring.upper().find(\"EST\")>0:\n",
    "        #print (\"Standard time: set timezone with UTC offset -5\")\n",
    "        ny_tz = dt.timezone(dt.timedelta(hours=-5))\n",
    "    elif timestring.upper().find(\"EDT\")>0:\n",
    "        #print (\"Daylight savings time: set timezone with UTC offset -4\")\n",
    "        ny_tz = dt.timezone(dt.timedelta(hours=-4))\n",
    "    #print(\"test:\" , timestring[0:10])\n",
    "    if not daily:\n",
    "        # hour information (hourly data)\n",
    "        t=dt.datetime.strptime(timestring[0:19],'%Y-%m-%d %H:%M:%S')\n",
    "        t=dt.datetime(t.year,t.month,t.day, t.hour, t.minute, t.second,tzinfo=ny_tz)\n",
    "    else:\n",
    "        t=dt.datetime.strptime(timestring[0:10],'%Y-%m-%d')\n",
    "        t=dt.datetime(t.year,t.month,t.day, 0, 0, 0,tzinfo=ny_tz)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interim-emphasis",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time(dfg,column='time_end'):\n",
    "    ntime=dfg.shape[0] # number of 1 hour observations\n",
    "    n=0\n",
    "    mytime=[] # new empty list later to convert into numpy array\n",
    "    while n<ntime:\n",
    "        timestring=dfg[column].iloc[n]\n",
    "        thelp=time_support(timestring)\n",
    "        mytime.append(thelp)\n",
    "        n=n+1\n",
    "    return mytime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operational-genius",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get for each day mean \n",
    "def get_daily_mean(time,data,startindex=0,test=False):\n",
    "    \"\"\"calculates for all days the mean value\n",
    "    \n",
    "    The hourly data are analyzed in 24 hour intervals\n",
    "    and the mean data values are calculated using 24 time windows.\n",
    "    The 24 period depends on the start position in the arrays. \n",
    "    Use the optional parameter to adjust the 24-hour intervals to \n",
    "    the preferred  day ranges.\n",
    "    \n",
    "    Input parameter:\n",
    "        time (1-d numpy array): array with datetime values\n",
    "        data (1-d numpy array): array with corresponding data values\n",
    "        startindex (integer): optional parameter to change the start position in the arrays\n",
    "        test (boolean): if True then this function prints some diagnostics to the screen\n",
    "                        (defaut it is set False)\n",
    "    Returns:\n",
    "        day, mean:  numpy arrays (new size) with the dates (days) and daily mean\n",
    "    \"\"\"    \n",
    "    d0=time[0]\n",
    "    day0=d0.day\n",
    "    hour0=d0.hour\n",
    "    d1=d0+dt.timedelta(1)\n",
    "    time_ret=[]\n",
    "    mean_ret=[]\n",
    "    while d0<=time[-1]:\n",
    "        ifind=np.logical_and(time>=d0,time<d1)\n",
    "        mtime=d0+(d1-d0)/2 # center time of the 24h window\n",
    "        mdata=data[ifind].mean()\n",
    "        time_ret.append(mtime)\n",
    "        mean_ret.append(mdata)\n",
    "        if test:\n",
    "            print(\"date-range used: \")\n",
    "            print(d0.strftime(\"%Y-%m-%d %H:%M:%S\") + \" to \" + d1.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "            print(mtime.strftime(\"%Y-%m-%d\"),np.round(mdata,4))\n",
    "        # increment start and end dates by +24h\n",
    "        d0=d1\n",
    "        d1=d1+dt.timedelta(1)\n",
    "    return np.array(time_ret), np.array(mean_ret)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-desperate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get from each day the min value\n",
    "def get_daily_min(time,data,startindex=0,test=False):\n",
    "    \"\"\"calculates for all days the min value\n",
    "    \n",
    "    The hourly data are analyzed in 24 hour intervals\n",
    "    and the min data values are calculated using 24 time windows.\n",
    "    The 24 period depends on the start position in the arrays. \n",
    "    Use the optional parameter to adjust the 24-hour intervals to \n",
    "    the preferred  day ranges.\n",
    "    \n",
    "    Input parameter:\n",
    "        time (1-d numpy array): array with datetime values\n",
    "        data (1-d numpy array): array with corresponding data values\n",
    "        startindex (integer): optional parameter to change the start position in the arrays\n",
    "        test (boolean): if True then this function prints some diagnostics to the screen\n",
    "                        (defaut it is set False)\n",
    "    Returns:\n",
    "        day, min:  numpy arrays (new size) with the dates (days) and daily min\n",
    "    \"\"\"    \n",
    "    d0=time[0]\n",
    "    day0=d0.day\n",
    "    hour0=d0.hour\n",
    "    d1=d0+dt.timedelta(1)\n",
    "    time_ret=[]\n",
    "    min_ret=[]\n",
    "    while d0<=time[-1]:\n",
    "        ifind=np.logical_and(time>=d0,time<d1)\n",
    "        mtime=d0+(d1-d0)/2 # center time of the 24h window\n",
    "        mdata=data[ifind].min()\n",
    "        time_ret.append(mtime)\n",
    "        min_ret.append(mdata)\n",
    "        if test:\n",
    "            print(\"date-range used: \")\n",
    "            print(d0.strftime(\"%Y-%m-%d %H:%M:%S\") + \" to \" + d1.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "            print(mtime.strftime(\"%Y-%m-%d\"),np.round(mdata,4))\n",
    "        # increment start and end dates by +24h\n",
    "        d0=d1\n",
    "        d1=d1+dt.timedelta(1)\n",
    "    return np.array(time_ret), np.array(min_ret)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "written-baseline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get from each day the max value\n",
    "def get_daily_max(time,data,startindex=0,test=False):\n",
    "    \"\"\"calculates for all days the max value\n",
    "    \n",
    "    The hourly data are analyzed in 24 hour intervals\n",
    "    and the max data values are calculated using 24 time windows.\n",
    "    The 24 period depends on the start position in the arrays. \n",
    "    Use the optional parameter to adjust the 24-hour intervals to \n",
    "    the preferred  day ranges.\n",
    "    \n",
    "    Input parameter:\n",
    "        time (1-d numpy array): array with datetime values\n",
    "        data (1-d numpy array): array with corresponding data values\n",
    "        startindex (integer): optional parameter to change the start position in the arrays\n",
    "        test (boolean): if True then this function prints some diagnostics to the screen\n",
    "                        (defaut it is set False)\n",
    "    Returns:\n",
    "        day, max:  numpy arrays (new size) with the dates (days) and daily max\n",
    "    \"\"\"    \n",
    "    d0=time[0]\n",
    "    day0=d0.day\n",
    "    hour0=d0.hour\n",
    "    d1=d0+dt.timedelta(1)\n",
    "    time_ret=[]\n",
    "    max_ret=[]\n",
    "    while d0<=time[-1]:\n",
    "        ifind=np.logical_and(time>=d0,time<d1)\n",
    "        mtime=d0+(d1-d0)/2 # center time of the 24h window\n",
    "        mdata=data[ifind].max()\n",
    "        time_ret.append(mtime)\n",
    "        max_ret.append(mdata)\n",
    "        if test:\n",
    "            print(\"date-range used: \")\n",
    "            print(d0.strftime(\"%Y-%m-%d %H:%M:%S\") + \" to \" + d1.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "            print(mtime.strftime(\"%Y-%m-%d\"),np.round(mdata,4))\n",
    "        # increment start and end dates by +24h\n",
    "        d0=d1\n",
    "        d1=d1+dt.timedelta(1)\n",
    "    return np.array(time_ret), np.array(max_ret)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anonymous-ukraine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the data and show the data table\n",
    "shared_data_folder=\"/home11/staff/timm/Public/Data/\"\n",
    "subfolder=\"MESONET/\"\n",
    "\n",
    "# open one example file month December 2020 (202012)\n",
    "# file names are in in format YYYYMM.csv with YYYY the 4-digit year\n",
    "# and MM the two digit month with leading zeros\n",
    "\n",
    "# creates list with year and months represented as strings\n",
    "years= [ '%4.4d' %(yr+2017) for yr in range (4) ]\n",
    "months=[ '%2.2d' %(m+1) for m in range(12)]\n",
    "\n",
    "\n",
    "filelist=[]\n",
    "\n",
    "# do one year at a time - better for daily stats on concatenated data frames\n",
    "# jumps in time stepping between years not handled by the functions\n",
    "# that create daily statistics.\n",
    "print(\">>>> USER INPUT <<<<\")\n",
    "yr=input(\"enter a year you want to analyze (2018,2019,or 2020):\")\n",
    "\n",
    "for m in months[5:8]:\n",
    "        filelist.append(yr+m+'.csv')\n",
    "filelist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eight-mechanics",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "## We use the methods and objects provided in package Pandas\n",
    " to import spreadsheet table data (text files in CSV format)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial-integer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one filecontains hourly data for one months from all 126 stations in NY.\n",
    "# one can use two methods to select just the data from one station\n",
    "# open the file and create a 'big' spreadsheet-like data object\n",
    "\n",
    "frames=[]\n",
    "for filename in filelist:\n",
    "    folder=shared_data_folder+subfolder \n",
    "    print(\"open file \"+folder+filename)\n",
    "    df0=pd.read_csv(folder+filename)\n",
    "    frames.append(df0.copy())\n",
    "# season data into one data frame.\n",
    "df= pd.concat(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "domestic-democrat",
   "metadata": {},
   "source": [
    "## Here we select now one station after another to create daily time series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organizational-panama",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the first couple of rows of the spreadsheet table (top part)\n",
    "df.head()\n",
    "dfg=df.groupby(\"station\")\n",
    "\n",
    "# To see all available station ID strings:\n",
    "# you can use the list station_ids\n",
    "\n",
    "station_ids=dfg.groups.keys()\n",
    "# create a column oriented table (126 stations in columns)\n",
    "buffer={} # use dictionary to give columns their station ID names\n",
    "for i,sid in enumerate(station_ids):\n",
    "    print(f\"\\r {i} {sid} \\t\",end=\"\")\n",
    "    dfg1=dfg.get_group(sid)\n",
    "    time1=np.array(get_time(dfg1))\n",
    "    # we select two data columns with meteorological observations\n",
    "    # 2m air temperature (1 hour maximum and 1 hour minimum values)\n",
    "    dtime1, dtmin1=get_daily_min(time1,dfg1[\"temp_2m_min [degC]\"].values)\n",
    "    buffer[sid]=dtmin1\n",
    "# finally adding the time coordinates \n",
    "#(without further checking we assume all stations\n",
    "# report at the same time)\n",
    "print(\"Done with processing hourly data ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "casual-organization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can add time if needed but for summary statistics on the station columns \n",
    "# we can leave it out\n",
    "# buffer['time']=dtime1\n",
    "dfout=pd.DataFrame(buffer)\n",
    "dfout.shape\n",
    "\n",
    "outfile=\"tmin_jja_\"+yr+\".cvs\"\n",
    "dfout.to_csv(outfile)\n",
    "print(\"exported daily min temp data from JJA season to CSV file \"+outfile)\n",
    "dfout.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unknown-minority",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate number of station days with temp > 35 deg C\n",
    "# we need to do two important data process selections\n",
    "# on the temperature arrays for each station\n",
    "# (1) check for nan values and subsample the good data from array temp\n",
    "# (2) find the good data values where the critical temperature is exceeded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greenhouse-birthday",
   "metadata": {},
   "outputs": [],
   "source": [
    "tcrit=20.0\n",
    "itotal=0\n",
    "# collect all hot temperature values in list\n",
    "t_list = []\n",
    "record_max=-300 # used to find record max temperature\n",
    "for c in dfout.columns:\n",
    "    temp=dfout[c].values.flatten()\n",
    "    # remove np.nan\n",
    "    iuse=np.logical_not(np.isnan(temp))\n",
    "    tuse=temp[iuse]\n",
    "    ihot=tuse>tcrit\n",
    "    itotal=itotal+np.sum(ihot)\n",
    "    #print (c,tuse[ihot],itotal)\n",
    "    if np.max(tuse>record_max):\n",
    "        record_max=np.max(tuse)\n",
    "        record_station=c\n",
    "    if any(ihot):\n",
    "        for t in tuse[ihot]:\n",
    "                t_list.append(t)\n",
    "        print (t_list)\n",
    "t_array=np.array(t_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heard-possible",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(80*\"=\")\n",
    "print(\"total station days with daily min temp > \"+str(tcrit)+\" : \"+str(len(t_list)))\n",
    "print(\"highest tmin: \"+str(record_max)+\" deg C\")\n",
    "print(\"observed at station \"+record_station)\n",
    "print(80*\"=\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fluid-delicious",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 June 2020 Environment",
   "language": "python",
   "name": "jun20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
